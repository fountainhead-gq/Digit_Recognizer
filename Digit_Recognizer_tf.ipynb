{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "# test = pd.read_csv('test.csv')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获得特征和标签\n",
    "X_train = train.drop('label', axis=1)\n",
    "Y_train = train['label']\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize 正则化,==>[0,1]\n",
    "def normalize(x):\n",
    "    X_normale = (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "    return X_normale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize2(x):\n",
    "    X_normale = (x-x.mean(x))/x.std()\n",
    "    return X_normale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 显示图片\n",
    "def display_image(image_data):\n",
    "    plt.imshow(image_data.reshape((28, 28)));\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAdjrm/Qn6GtYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd5e96d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_data = X_train.values\n",
    "display_image(image_data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 处理数据\n",
    "X_train = normalize(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAdjrm/Qn6GtYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd492278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_image(X_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one hot\n",
    "\n",
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(range(10))\n",
    "\n",
    "# convert labels to one-hot \n",
    "# 0 => [1 0 0 0 0 0 0 0 0 0]\n",
    "# 1 => [0 1 0 0 0 0 0 0 0 0]\n",
    "# ...\n",
    "# 9 => [0 0 0 0 0 0 0 0 0 1]\n",
    "def one_hot_encode(x):\n",
    "    one_hot = lb.transform(x)\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = one_hot_encode(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np.array(Y_train)\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39900, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# images\n",
    "x = tf.placeholder('float', shape=[None, X_train.shape[1]], name='image')\n",
    "# labels\n",
    "y = tf.placeholder('float', shape=[None, Y_train.shape[1]], name='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# (42000,784) => (42000,28,28,1)\n",
    "# reshape to 4d tensor\n",
    "image_width = 28\n",
    "image_height = 28\n",
    "\n",
    "# Input/Image\n",
    "image = tf.reshape(x, [-1, image_width, image_height, 1])\n",
    "print (image.get_shape()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Convolution filter\n",
    "# filter_size_width = 5\n",
    "# filter_size_height = 5\n",
    "# conv_num_outputs = 32\n",
    "# color_channels = 1\n",
    "\n",
    "# # Input/Image\n",
    "# # x_input = tf.placeholder(tf.float32, shape=[None, 28, 28, color_channels])\n",
    "\n",
    "# # Weight and bias\n",
    "# weight = tf.Variable(tf.truncated_normal([filter_size_height, filter_size_width, color_channels, conv_num_outputs]))\n",
    "# bias = tf.Variable(tf.zeros(conv_num_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weight\n",
    "def conv_weight(filter_size_height, filter_size_width, color_channels, conv_num_outputs):\n",
    "    return tf.Variable(tf.truncated_normal([filter_size_height, filter_size_width, color_channels, conv_num_outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bias\n",
    "def conv_bias(conv_num_outputs):\n",
    "    return tf.Variable(tf.zeros(conv_num_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convolution\n",
    "def conv2d(x, weight):\n",
    "    return tf.nn.conv2d(x, weight, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pooling\n",
    "# [[0,3],\n",
    "#  [4,2]] => 4\n",
    "\n",
    "def max_pool(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conv \n",
    "# conv_layer = conv2d(image, weight)\n",
    "# conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "# conv_layer = tf.nn.relu(conv_layer)\n",
    "# print(conv_layer.get_shape())\n",
    "\n",
    "# Set the CNN model \n",
    "# [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 28, 28, 32)\n",
      "(?, 14, 14, 32)\n"
     ]
    }
   ],
   "source": [
    "# first convolutional layer\n",
    "\n",
    "weight = conv_weight(5, 5, 1, 32)\n",
    "bias = conv_bias(32)\n",
    "\n",
    "# conv2d \n",
    "conv_layer = conv2d(image, weight)\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "conv_layer = tf.nn.relu(conv_layer)\n",
    "print(conv_layer.get_shape())\n",
    "\n",
    "# Max Pooling\n",
    "conv_layer = max_pool(conv_layer)\n",
    "print(conv_layer.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 14, 14, 64)\n",
      "(?, 7, 7, 64)\n"
     ]
    }
   ],
   "source": [
    "# second convolutional layer\n",
    "weight = conv_weight(3, 3, 32, 64)\n",
    "bias = conv_bias(64)\n",
    "\n",
    "# conv2d\n",
    "conv_layer = conv2d(conv_layer, weight)\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "conv_layer = tf.nn.relu(conv_layer)\n",
    "print(conv_layer.get_shape())\n",
    "\n",
    "# Second Max Pooling\n",
    "conv_layer = max_pool(conv_layer)\n",
    "print(conv_layer.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dropout\n",
    "conv_layer = tf.nn.dropout(conv_layer, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 3136)\n"
     ]
    }
   ],
   "source": [
    "x_flatten = tf.contrib.layers.flatten(conv_layer)\n",
    "print(x_flatten.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 256)\n"
     ]
    }
   ],
   "source": [
    "fc_layer = tf.contrib.layers.fully_connected(x_flatten, 256, activation_fn=tf.nn.relu)\n",
    "print(fc_layer.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_out = tf.nn.dropout(fc_layer, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "output = tf.contrib.layers.fully_connected(drop_out, 10, activation_fn=None)\n",
    "print(output.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "logits = output\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "# defalut learning_rate=0.001\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0005).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_features_labels(batch_size):\n",
    "    start = 0\n",
    "    shuf = np.arange(len(X_train))\n",
    "    np.random.shuffle(shuf)\n",
    "    features = X_train[shuf]\n",
    "    labels = Y_train[shuf]\n",
    "    end = min(start + batch_size, len(X_train))    \n",
    "    return features[start:end], labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "test = normalize(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array(test)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 201\n",
    "batch_size = 128\n",
    "keep_probability = 0.75\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setp 0,the train accuracy: 0.2734375\n",
      "setp 50,the train accuracy: 0.9765625\n",
      "setp 100,the train accuracy: 0.984375\n",
      "setp 150,the train accuracy: 0.9921875\n",
      "Testing Accuracy: 0.9809523820877075\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    total_batch = math.ceil(len(X_train)/batch_size)\n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_x = X_train[batch_size*i:batch_size*(i+1)]\n",
    "            batch_y = Y_train[batch_size*i:batch_size*(i+1)]\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob: keep_probability})     \n",
    "            \n",
    "#         batch_x, batch_y = batch_features_labels(batch_size)\n",
    "#         sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: keep_probability})\n",
    "#         # Calculate batch loss and accuracy\n",
    "#         loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            valid_acc = sess.run(accuracy, feed_dict={x: X_train[:batch_size],\n",
    "                                                      y: Y_train[:batch_size],\n",
    "                                                      keep_prob: 1.})\n",
    "            print('epoch {},the train accuracy: {}'.format(epoch, valid_acc))\n",
    "\n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={x: X_test,\n",
    "                                             y: Y_test,\n",
    "                                             keep_prob: 1.})\n",
    "    \n",
    "    print('Testing Accuracy: {}'.format(test_acc))\n",
    "    \n",
    "    # save\n",
    "    save_dir = 'save/dig_save'\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_dir)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # test 1\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     test_prob = sess.run(logits,feed_dict={x: test})\n",
    "#     test_labels = np.argmax(test_prob, axis=1)\n",
    "    \n",
    "#     submission = pd.DataFrame(data = {'ImageId':(np.arange(test_labels.shape[0])+1),'Label':test_labels})\n",
    "#     submission.to_csv('digit_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/dig_save\n"
     ]
    }
   ],
   "source": [
    "# test result \n",
    "loaded_Graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_Graph) as sess:\n",
    "    loader = tf.train.import_meta_graph(save_dir +'.meta')\n",
    "    loader.restore(sess, save_dir)    \n",
    "    # get tensors\n",
    "    loaded_x = loaded_Graph.get_tensor_by_name('image:0')\n",
    "    loaded_y = loaded_Graph.get_tensor_by_name('label:0')\n",
    "    loaded_prob = loaded_Graph.get_tensor_by_name('logits:0')\n",
    "    \n",
    "    test_prob = sess.run(tf.argmax(loaded_prob,1), feed_dict = {loaded_x: test})    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data = {'ImageId':(np.arange(test_prob.shape[0])+1),'Label':test_prob})\n",
    "submission.to_csv('digit_submission0.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
